---
title: "Single WAV File Analysis with ASAP"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Single WAV File Analysis with ASAP}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 10,
  fig.height = 5,
  out.width = "100%"
)
```

## Introduction

This vignette demonstrates how to use ASAP functions for analyzing single WAV 
files of zebra finch vocalizations. While ASAP is designed for large-scale 
longitudinal studies, all core analysis functions work directly with individual 
audio files, making it easy to explore and understand your data.

We'll cover:

1. **Audio Visualization** - View spectrograms
2. **Bout Detection** - Find singing periods
3. **Syllable Segmentation** - Detect individual syllables
4. **Spectral Entropy** - Measure spectral structure
5. **Fundamental Frequency** - Extract pitch contours
6. **Amplitude Envelope** - Analyze temporal dynamics

## Setup

```{r setup}
library(ASAP)

# Get path to example WAV file included with the package
wav_file <- system.file("extdata", "zf_example.wav", package = "ASAP")
```

## 1. Audio Visualization

The `visualize_song()` function creates spectrogram visualizations of audio 
recordings. This is typically the first step in exploring your data.

### Full recording

```{r visualize-full, fig.height=4}
# Visualize the entire recording
visualize_song(wav_file)
```

### Specific time window

You can focus on a specific time range using `start_time_in_second` and 
`end_time_in_second`:

```{r visualize-segment, fig.height=4}
# Visualize a 3-second segment
visualize_song(wav_file, 
               start_time_in_second = 1, 
               end_time_in_second = 4)
```

## 2. Bout Detection

A "bout" is a continuous period of singing. The `find_bout()` function 
automatically detects bout boundaries using RMS (root mean square) amplitude 
thresholding with bandpass filtering.

```{r find-bout}
# Detect bouts in the recording
bouts <- find_bout(wav_file, 
                   rms_threshold = 0.1,    # Amplitude threshold (0-1)
                   min_duration = 0.7,      # Minimum bout length in seconds
                   plot = TRUE)             # Show detection plot

# View detected bouts as a table
knitr::kable(bouts, digits = 3)
```

### Key parameters

- `rms_threshold`: Higher values require louder sounds; lower values detect 
  quieter vocalizations
- `min_duration`: Minimum bout length (filters out short sounds/noise)
- `freq_range`: Bandpass filter range (default: 1-8 kHz for zebra finch)

## 3. Syllable Segmentation

The `segment()` function detects individual syllables within a specified time 
window using dynamic spectral thresholding.

```{r segment, fig.height=6}
# Segment syllables in a time window
syllables <- segment(wav_file, 
                     start_time = 1,          # Start time (seconds)
                     end_time = 5,            # End time (seconds)
                     flim = c(1, 8),          # Frequency limits (kHz)
                     silence_threshold = 0.01,
                     min_syllable_ms = 20,    # Minimum syllable duration
                     max_syllable_ms = 240,   # Maximum syllable duration
                     min_level_db = 10,       # Starting threshold (dB)
                     verbose = FALSE)

# View detected syllables as a table
knitr::kable(syllables, digits = 3)
```

### Understanding the output

The returned data frame contains:

- `start_time`/`end_time`: Syllable boundaries (seconds)
- `duration`: Syllable length
- `silence_gap`: Gap before the next syllable (useful for syntax analysis)
- `selec`: Selection number for tracking

## 4. Spectral Entropy Analysis

Spectral entropy measures the "randomness" or structure in the frequency 
distribution. Harmonic sounds (like syllables) have low entropy, while noisy 
sounds have high entropy.

```{r spectral-entropy, fig.height=5}
# Calculate spectral entropy for a segment
entropy_result <- spectral_entropy(wav_file,
                                   start_time = 1.5,
                                   end_time = 2.5,
                                   method = "wiener",  # or "shannon"
                                   normalize = TRUE,
                                   plot = TRUE)
```

### Interpreting entropy values

- **Low entropy (near 0)**: Structured, harmonic sounds (e.g., tonal syllables)
- **High entropy (near 1)**: Noisy, unstructured sounds (e.g., calls, noise)

### Available methods

- `"wiener"`: Wiener entropy (ratio of geometric to arithmetic mean)
- `"shannon"`: Shannon entropy (information-theoretic measure)

## 5. Fundamental Frequency (Pitch) Analysis

The `FF()` function extracts the fundamental frequency (F0) contour, which 
represents the perceived pitch of the vocalization over time.

```{r fundamental-frequency, fig.height=5}
# Extract fundamental frequency
pitch_result <- FF(wav_file,
                   start_time = 1.5,
                   end_time = 2.5,
                   method = "cepstrum",  # Cepstral analysis
                   fmax = 1400,          # Maximum F0 to detect (Hz)
                   threshold = 10,       # Confidence threshold
                   plot = TRUE)
```

### Key parameters

- `fmax`: Maximum fundamental frequency to detect (1400 Hz typical for zebra 
  finch)
- `threshold`: Higher values filter out uncertain estimates
- `method`: `"cepstrum"` (default) or `"yin"` (requires Python librosa)

### The result contains:

- `f0`: Fundamental frequency values over time
- `time`: Corresponding time stamps

## 6. Amplitude Envelope

The amplitude envelope represents the temporal dynamics of sound intensity. 
Use `amp_env()` on segmented data to extract envelope profiles.

```{r amplitude-envelope-bout, fig.height=4}
# Extract amplitude envelope for the second bout
if (!is.null(bouts) && nrow(bouts) >= 2) {
  env_bout <- amp_env(bouts[2, ], 
                      wav_dir = dirname(wav_file),
                      msmooth = c(256, 50),
                      norm = TRUE,
                      plot = TRUE)
}
```

We can also extract the envelope for individual syllables:

```{r amplitude-envelope-syllable, fig.height=4}
# Extract amplitude envelope for the 7th syllable
if (!is.null(syllables) && nrow(syllables) >= 7) {
  env_syl <- amp_env(syllables[7, ], 
                     wav_dir = dirname(wav_file),
                     msmooth = c(256, 50),
                     norm = TRUE,
                     plot = TRUE)
}
```

### Smoothing parameters

The `msmooth` argument controls envelope smoothing:

- First value: Window length (samples)
- Second value: Overlap percentage

## Putting It All Together

Here's a typical workflow for single-file analysis:

```{r workflow, eval=FALSE}
library(ASAP)

# 1. Load and visualize
wav_file <- "path/to/your/recording.wav"
visualize_song(wav_file, start_time_in_second = 0, end_time_in_second = 10)

# 2. Detect bouts
bouts <- find_bout(wav_file, rms_threshold = 0.1, min_duration = 0.7)

# 3. Segment syllables
if (!is.null(bouts) && nrow(bouts) > 0) {
  syllables <- segment(wav_file,
                       start_time = bouts$start_time[1],
                       end_time = bouts$end_time[1],
                       min_level_db = 10)
}

# 4. Analyze acoustic features
entropy <- spectral_entropy(wav_file, 
                            start_time = bouts$start_time[1],
                            end_time = bouts$end_time[1])

pitch <- FF(wav_file,
            start_time = bouts$start_time[1],
            end_time = bouts$end_time[1])

# 5. Extract amplitude envelope
env <- amp_env(bouts[1, ], 
               wav_dir = dirname(wav_file),
               msmooth = c(256, 50),
               norm = TRUE,
               plot = TRUE)
```


## Session Info

```{r session-info}
sessionInfo()
```
